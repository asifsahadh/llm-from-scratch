{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d2ac6c",
   "metadata": {},
   "source": [
    "### INSTRUCTION FINETUNING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67453866",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88cf17",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7ae605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import time\n",
    "from functools import partial\n",
    "from gpt_download import download_and_load_gpt2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08340f",
   "metadata": {},
   "source": [
    "Get the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aae9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fea4e",
   "metadata": {},
   "source": [
    "Class to create the dataset for out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9534c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_len, stride): # max_len is context size\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # tokenize the text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
    "\n",
    "        # sliding window to create overlapping sequences\n",
    "        for i in range(0, len(token_ids) - max_len, stride):\n",
    "            input_chunk = token_ids[i:i + max_len]\n",
    "            target_chunk = token_ids[i + 1:i + max_len + 1]\n",
    "            self.input_ids.append(input_chunk)\n",
    "            self.target_ids.append(target_chunk)\n",
    "    \n",
    "    # the below 2 methods is required for Dataloader to be used\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx): # we are basically saying that if the input is the 50th tensor, then the output is the 50th tensor\n",
    "        return (\n",
    "            torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            torch.tensor(self.target_ids[idx], dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af064a2",
   "metadata": {},
   "source": [
    "Helper function to create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a7cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size = 4, max_len = 256, stride = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
    "    # drop last if last tensor is shorter than max_len\n",
    "    # batch size is the number of training ip-op data pairs to be used for training by whcih the parameters are updated\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = DatasetV1(txt, tokenizer, max_len, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c54e9f",
   "metadata": {},
   "source": [
    "The MHA class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30137f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_len, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        # s2\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        # s3\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_len, context_len), diagonal = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_out = x.shape # s1\n",
    "\n",
    "        # s4\n",
    "        keys = self.W_k(x)\n",
    "        queries = self.W_q(x)\n",
    "        values = self.W_v(x)\n",
    "        \n",
    "        # s5\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # s6\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # s7\n",
    "        attention_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
    "        attention_weights = self.dropout(attention_weights) # s8\n",
    "\n",
    "        context_vec = (attention_weights @ values).transpose(1, 2) # s9 & s10\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # s11\n",
    "        context_vec = self.out_proj(context_vec) # optional\n",
    " \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562ddc5",
   "metadata": {},
   "source": [
    "Classes for layer norm, GELU activation function & feed forwards network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb87cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False) # unbiased so var is divided by n-1\n",
    "        norm = (x - mean) / (torch.sqrt(var + self.eps)) # epsilon to prevent division by 0\n",
    "        return self.scale * norm + self.shift # element wise operations - trainable parameters to learn appropriate scaling and shifting of norm values that best suits the data\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # expansion\n",
    "            GELU(), # activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # contraction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d497",
   "metadata": {},
   "source": [
    "The transformer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62c536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention( # converts input to context vectors  \n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_len = cfg[\"context_len\"],\n",
    "            num_heads = cfg[\"num_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # MHA\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x) # shape: [batch size, num tokens, emb size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # f(x) + x\n",
    "\n",
    "        # FCL\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # f(x) + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0165ba",
   "metadata": {},
   "source": [
    "The SLM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbe595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLM(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_len\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_idx): # input batch\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3664aa5",
   "metadata": {},
   "source": [
    "Helper function when generating text during each epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59ab6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): # idx is the input batch\n",
    "    for _ in range(max_new_tokens):\n",
    "        # crop current context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # get predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # batch_size x tokens_num x vocab_size\n",
    "        # get the last time step (last set of logits)\n",
    "        logits = logits[:, -1, :]\n",
    "        # apply softmax\n",
    "        probs = torch.softmax(logits, dim = -1)\n",
    "        # get id of max\n",
    "        idx_next = torch.argmax(probs, dim = -1, keepdim = True)\n",
    "        # append id to running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim = -1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306da6",
   "metadata": {},
   "source": [
    "Configure model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6172c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLM_CONFIG = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_len\" : 512,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"num_heads\" : 8,\n",
    "    \"n_layers\" : 8,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae7919",
   "metadata": {},
   "source": [
    "Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bcbb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLM(SLM_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9f724",
   "metadata": {},
   "source": [
    "Function for encoding & decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257c7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263e606",
   "metadata": {},
   "source": [
    "Function to implement decoding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28bfab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature = 0.0, top_k = None, eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, \n",
    "                torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "            \n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdb43a",
   "metadata": {},
   "source": [
    "Get OpenAI weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b40f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807976f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size = \"124M\", models_dir = \"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6e0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "Token embedding weight tensor dimention: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Settings: {settings}\")\n",
    "print(f\"Parameter dictionary keys: {params.keys()}\")\n",
    "print(f\"Token embedding weight tensor dimention: {params[\"wte\"].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12b8b64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SLM(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\" : {\"emb_dim\" : 768, \"n_layers\" : 12, \"n_heads\" : 12},\n",
    "    # add more for experimentation...   \n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = SLM_CONFIG.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_len\" : 1024, \"qkv_bias\" : True})\n",
    "\n",
    "model = SLM(NEW_CONFIG)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dead093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4e603cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(l, r):\n",
    "    if l.shape != r.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {l.shape}, Right: {r.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a3a7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_model(model, params):\n",
    "    model.pos_emb.weight = assign(model.pos_emb.weight, params['wpe'])\n",
    "    model.tok_emb.weight = assign(model.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params['blocks'])):\n",
    "\n",
    "        # q, k & v weight matrices\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis = -1 # from downloaded model weights\n",
    "        )\n",
    "        model.trf_blocks[b].attn.W_q.weight = assign(\n",
    "            model.trf_blocks[b].attn.W_q.weight, q_w.T\n",
    "        )\n",
    "        model.trf_blocks[b].attn.W_k.weight = assign(\n",
    "            model.trf_blocks[b].attn.W_k.weight, k_w.T\n",
    "        )\n",
    "        model.trf_blocks[b].attn.W_v.weight = assign(\n",
    "            model.trf_blocks[b].attn.W_v.weight, v_w.T\n",
    "        )\n",
    "\n",
    "        # q, k & v bias\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis = -1 # from downloaded model weights\n",
    "        )\n",
    "        model.trf_blocks[b].attn.W_q.bias = assign(\n",
    "            model.trf_blocks[b].attn.W_q.bias, q_b\n",
    "        )\n",
    "        model.trf_blocks[b].attn.W_k.bias = assign(\n",
    "            model.trf_blocks[b].attn.W_k.bias, k_b\n",
    "        )\n",
    "        model.trf_blocks[b].attn.W_v.bias = assign(\n",
    "            model.trf_blocks[b].attn.W_v.bias, v_b\n",
    "        )\n",
    "\n",
    "        # output projection weights from attention (fused q, k, v weights & bias)\n",
    "        model.trf_blocks[b].attn.out_proj.weight = assign(\n",
    "            model.trf_blocks[b].attn.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        model.trf_blocks[b].attn.out_proj.bias = assign(\n",
    "            model.trf_blocks[b].attn.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # feed forward (expantsion & contraction)\n",
    "        model.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            model.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        model.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            model.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        model.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            model.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        model.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            model.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # shift & scale of layernorm\n",
    "        model.trf_blocks[b].norm1.scale = assign(\n",
    "            model.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        model.trf_blocks[b].norm1.shift = assign(\n",
    "            model.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        model.trf_blocks[b].norm2.scale = assign(\n",
    "            model.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        model.trf_blocks[b].norm2.shift = assign(\n",
    "            model.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "\n",
    "    model.final_norm.scale = assign(model.final_norm.scale, params[\"g\"])\n",
    "    model.final_norm.shift = assign(model.final_norm.shift, params[\"b\"])\n",
    "    model.out_head.weight = assign(model.out_head.weight, params[\"wte\"]) # weight tying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3812736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1355: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:35.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SLM(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_model(model, params)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e09b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Everytime I see you as usual the most valuable time because I was always wanting to make sure something that I knew it would become you mayonnaise\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model = model, \n",
    "    idx = text_to_token_ids(\"Everytime I see you\", tokenizer).to(device),\n",
    "    max_new_tokens = 25,\n",
    "    context_size = NEW_CONFIG[\"context_len\"],\n",
    "    top_k = 50,\n",
    "    temperature = 1.5\n",
    ")\n",
    "\n",
    "print(\"Output:\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67ba68",
   "metadata": {},
   "source": [
    "Get dataset for instruction fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c48b0115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n",
      "\n",
      "Sample Data\n",
      "-----------\n",
      "Instruction: Identify the correct spelling of the following word.\n",
      "Input: Ocassion\n",
      "Output: The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context = ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n",
    "print()\n",
    "print(\"Sample Data\")\n",
    "print('-----------')\n",
    "print(\"Instruction:\", data[50]['instruction'])\n",
    "print(\"Input:\", data[50]['input'])\n",
    "print(\"Output:\", data[50]['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686be95",
   "metadata": {},
   "source": [
    "Conver to Alpaca format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49852bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d75b1d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c099236",
   "metadata": {},
   "source": [
    "Train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcefff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 110 55\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "val_portion = int(len(data) * 0.10)\n",
    "test_portion = len(data) - (train_portion + val_portion)\n",
    "\n",
    "print(train_portion, val_portion, test_portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4e3e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:train_portion]\n",
    "val_data = data[train_portion:train_portion + val_portion]\n",
    "test_data = data[train_portion + val_portion:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1b18c",
   "metadata": {},
   "source": [
    "Data batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58f04f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            ) \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75469be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id = 256, device = \"cpu\"):\n",
    "    batch_max_len = max(len(item) + 1 for item in batch) # why add by 1?\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id] # thsi helps us when making the target as it has the EOF token at the end anyway (check notes ot know why)\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_len - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1]) # we remove that last EOF token here since this is the input\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4baea8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2,   3,   4,   5, 256, 256, 256, 256],\n",
      "        [  2,   4,   6,   8,  10,  12,  14,  16,  18],\n",
      "        [  3,   6, 256, 256, 256, 256, 256, 256, 256]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "input_1 = [1, 2, 3, 4, 5]\n",
    "input_2 = [2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "input_3 = [3, 6]\n",
    "batch = (input_1, input_2, input_3)\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ede398a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id = 50256, device = \"cpu\"):\n",
    "    batch_max_len = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_len - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  \n",
    "        targets = torch.tensor(padded[1:])  # shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2548a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     2,     3,     4,     5, 50256, 50256, 50256, 50256],\n",
      "        [    2,     4,     6,     8,    10,    12,    14,    16,    18],\n",
      "        [    3,     6, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "\n",
      "tensor([[    2,     3,     4,     5, 50256, 50256, 50256, 50256, 50256],\n",
      "        [    4,     6,     8,    10,    12,    14,    16,    18, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871846eb",
   "metadata": {},
   "source": [
    "Final function that includes ignore index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "619bc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id = 50256, ignore_index = -100, allowed_max_len = None, device = \"cpu\"):\n",
    "    batch_max_len = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_len - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  \n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_len is not None:\n",
    "            inputs = inputs[:allowed_max_len]\n",
    "            targets = targets[:allowed_max_len]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad5e1e",
   "metadata": {},
   "source": [
    "_Note: Adding -100 is as though that sample does not exist. So we do not calculate the loss for that sample._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3fb4a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     2,     3,     4,     5, 50256, 50256, 50256, 50256],\n",
      "        [    2,     4,     6,     8,    10,    12,    14,    16,    18],\n",
      "        [    3,     6, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])\n",
      "\n",
      "tensor([[    2,     3,     4,     5, 50256,  -100,  -100,  -100,  -100],\n",
      "        [    4,     6,     8,    10,    12,    14,    16,    18, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8552",
   "metadata": {},
   "source": [
    "Making dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e498bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "customized_collate_fn = partial(custom_collate_fn, device = device, allowed_max_len = 1024) # does seperation of tasks when model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f025fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    drop_last = False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    drop_last = False,\n",
    "    num_workers = num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b9722",
   "metadata": {},
   "source": [
    "Loading pre-trained weights for fine tuning.<br><br>\n",
    "_Note: We will be using a larger model for better performance._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "34ced867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Ccheckpoint (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000016773CA7710>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\checkpoint\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cencoder.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000016773CA4C80>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\encoder.json\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Chparams.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000016773401430>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\hparams.json\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cmodel.ckpt.data-00000-of-00001 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000167733FB770>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\model.ckpt.data-00000-of-00001\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cmodel.ckpt.index (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000016773CA7320>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\model.ckpt.index\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cmodel.ckpt.meta (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000016773CA7C50>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\model.ckpt.meta\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cvocab.bpe (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000016773CA04A0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Please check the URL: https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\vocab.bpe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m NEW_CONFIG.update({\u001b[33m\"\u001b[39m\u001b[33mqkv_bias\u001b[39m\u001b[33m\"\u001b[39m : \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcontext_len\u001b[39m\u001b[33m\"\u001b[39m : \u001b[32m1024\u001b[39m})\n\u001b[32m     15\u001b[39m model_size = CHOOSE_MODEL.split(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m].lstrip(\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\"\u001b[39m).rstrip(\u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# just getting the param count\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m settings, params = \u001b[43mdownload_and_load_gpt2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\OneDrive\\Documents\\Fundamentals\\LLMs\\LLM from Scratch\\gpt_download.py:35\u001b[39m, in \u001b[36mdownload_and_load_gpt2\u001b[39m\u001b[34m(model_size, models_dir)\u001b[39m\n\u001b[32m     33\u001b[39m tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n\u001b[32m     34\u001b[39m settings = json.load(\u001b[38;5;28mopen\u001b[39m(os.path.join(model_dir, \u001b[33m\"\u001b[39m\u001b[33mhparams.json\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m params = \u001b[43mload_gpt2_params_from_tf_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_ckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m settings, params\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\OneDrive\\Documents\\Fundamentals\\LLMs\\LLM from Scratch\\gpt_download.py:78\u001b[39m, in \u001b[36mload_gpt2_params_from_tf_ckpt\u001b[39m\u001b[34m(ckpt_path, settings)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Iterate over each variable in the checkpoint\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m tf.train.list_variables(ckpt_path):\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Load the variable and remove singleton dimensions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     variable_array = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Process the variable name to extract relevant parts\u001b[39;00m\n\u001b[32m     81\u001b[39m     variable_name_parts = name.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# Skip the 'model/' prefix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\llm-scratch\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1487\u001b[39m, in \u001b[36m_squeeze_dispatcher\u001b[39m\u001b[34m(a, axis)\u001b[39m\n\u001b[32m   1482\u001b[39m     a = concatenate((a,) * repeats)[:new_size]\n\u001b[32m   1484\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_squeeze_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[32m   1491\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqueeze\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NEW_CONFIG = SLM_CONFIG.copy()\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "NEW_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "NEW_CONFIG.update({\"qkv_bias\" : True, \"context_len\" : 1024})\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\") # just getting the param count\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size = model_size,\n",
    "    models_dir = \"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf23f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SLM(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SLM(NEW_CONFIG)\n",
    "load_weights_into_model(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1226a4",
   "metadata": {},
   "source": [
    "_Example inference before fine tuning._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d848f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens = 40,\n",
    "    context_size = NEW_CONFIG[\"context_len\"],\n",
    "    eos_id = 50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111cf8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first thing to do.\n",
      "\n",
      "The second thing.\n",
      "\n",
      "The third thing.\n",
      "\n",
      "The fourth thing.\n",
      "\n",
      "The fifth thing.\n",
      "\n",
      "The fifth thing.\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92906ec1",
   "metadata": {},
   "source": [
    "Instruction finetuning training loop (reused code from pre-training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9aff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten()) # this does all the softmax & everything\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches = None): # this will show the loss of the LM\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches # mean loss per batch\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, test_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
    "        test_loss = calc_loss_loader(test_loader, model, device, num_batches = eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, test_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model, idx = encoded, max_new_tokens = 50, context_size = context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    print()\n",
    "    model.train() # set it back to training mode\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, test_loader, optimizer, device, \n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, test_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset gradients from previous batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel() # return number of tokens seen\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation (optional)\n",
    "            if global_step % eval_freq == 0: # only after a set of batches is used for training\n",
    "                train_loss, test_loss = evaluate_model(\n",
    "                    model, train_loader, test_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                test_losses.append(test_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch + 1} (Step {global_step:04d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Test loss {test_loss:.3f}\")\n",
    "            \n",
    "        # print sample text from each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "        \n",
    "    return train_losses, test_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccbfce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.992127799987793\n",
      "Validation loss: 5.115596675872803\n"
     ]
    }
   ],
   "source": [
    "# initial loss check\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches = 5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches = 5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 0000): Train loss 3.552, Test loss 3.625\n",
      "Epoch 1 (Step 0005): Train loss 1.663, Test loss 1.508\n",
      "Epoch 1 (Step 0010): Train loss 1.161, Test loss 1.187\n",
      "Epoch 1 (Step 0015): Train loss 1.095, Test loss 1.074\n",
      "Epoch 1 (Step 0020): Train loss 0.974, Test loss 1.001\n",
      "Epoch 1 (Step 0025): Train loss 0.939, Test loss 0.956\n",
      "Epoch 1 (Step 0030): Train loss 0.938, Test loss 0.917\n",
      "Epoch 1 (Step 0035): Train loss 0.861, Test loss 0.901\n",
      "Epoch 1 (Step 0040): Train loss 0.822, Test loss 0.886\n",
      "Epoch 1 (Step 0045): Train loss 0.748, Test loss 0.867\n",
      "Epoch 1 (Step 0050): Train loss 0.840, Test loss 0.860\n",
      "Epoch 1 (Step 0055): Train loss 0.915, Test loss 0.836\n",
      "Epoch 1 (Step 0060): Train loss 0.851, Test loss 0.813\n",
      "Epoch 1 (Step 0065): Train loss 0.768, Test loss 0.809\n",
      "Epoch 1 (Step 0070): Train loss 0.673, Test loss 0.808\n",
      "Epoch 1 (Step 0075): Train loss 0.674, Test loss 0.802\n",
      "Epoch 1 (Step 0080): Train loss 0.730, Test loss 0.802\n",
      "Epoch 1 (Step 0085): Train loss 0.640, Test loss 0.794\n",
      "Epoch 1 (Step 0090): Train loss 0.699, Test loss 0.784\n",
      "Epoch 1 (Step 0095): Train loss 0.625, Test loss 0.775\n",
      "Epoch 1 (Step 0100): Train loss 0.610, Test loss 0.771\n",
      "Epoch 1 (Step 0105): Train loss 0.687, Test loss 0.758\n",
      "Epoch 1 (Step 0110): Train loss 0.715, Test loss 0.750\n",
      "Epoch 1 (Step 0115): Train loss 0.626, Test loss 0.740\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a simile.  ### Input: The car is very fast.  ### Response: The car is fast.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the chemical formula for carbon dioxide?  ### Response\n",
      "\n",
      "Epoch 2 (Step 0120): Train loss 0.551, Test loss 0.740\n",
      "Epoch 2 (Step 0125): Train loss 0.586, Test loss 0.734\n",
      "Epoch 2 (Step 0130): Train loss 0.587, Test loss 0.737\n",
      "Epoch 2 (Step 0135): Train loss 0.524, Test loss 0.731\n",
      "Epoch 2 (Step 0140): Train loss 0.534, Test loss 0.728\n",
      "Epoch 2 (Step 0145): Train loss 0.496, Test loss 0.727\n",
      "Epoch 2 (Step 0150): Train loss 0.505, Test loss 0.723\n",
      "Epoch 2 (Step 0155): Train loss 0.558, Test loss 0.721\n",
      "Epoch 2 (Step 0160): Train loss 0.554, Test loss 0.718\n",
      "Epoch 2 (Step 0165): Train loss 0.527, Test loss 0.719\n",
      "Epoch 2 (Step 0170): Train loss 0.447, Test loss 0.721\n",
      "Epoch 2 (Step 0175): Train loss 0.455, Test loss 0.717\n",
      "Epoch 2 (Step 0180): Train loss 0.525, Test loss 0.716\n",
      "Epoch 2 (Step 0185): Train loss 0.539, Test loss 0.717\n",
      "Epoch 2 (Step 0190): Train loss 0.429, Test loss 0.720\n",
      "Epoch 2 (Step 0195): Train loss 0.467, Test loss 0.715\n",
      "Epoch 2 (Step 0200): Train loss 0.408, Test loss 0.715\n",
      "Epoch 2 (Step 0205): Train loss 0.472, Test loss 0.712\n",
      "Epoch 2 (Step 0210): Train loss 0.508, Test loss 0.714\n",
      "Epoch 2 (Step 0215): Train loss 0.518, Test loss 0.710\n",
      "Epoch 2 (Step 0220): Train loss 0.401, Test loss 0.706\n",
      "Epoch 2 (Step 0225): Train loss 0.471, Test loss 0.701\n",
      "Epoch 2 (Step 0230): Train loss 0.411, Test loss 0.696\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a simile.  ### Input: The car is very fast.  ### Response: The car is as fast as a bullet.<|endoftext|>The United States is the largest economy in the world. It is the largest economy in the world.<|endoftext|>The United States is the largest economy in the world.<|endoftext|>The\n",
      "\n",
      "Training completed in 36.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.00005, weight_decay = 0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs = num_epochs, eval_freq = 5, eval_iter = 5,\n",
    "    start_context = format_input(val_data[0]), tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Name the author of 'Pride and Prejudice'.  ### Response: The author of 'Pride and Prejudice' is Robert Frost.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_sample(model, tokenizer, device, format_input(val_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f97a6",
   "metadata": {},
   "source": [
    "Saving the weights for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ft-instruct.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9980193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SLM(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SLM(NEW_CONFIG)\n",
    "model.load_state_dict(torch.load(\"ft-instruct.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fcf827aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of Denmark?  ### Response: The capital of Denmark is Copenhagen.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of Sweden?  ### Response\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_sample(model, tokenizer, device, format_input(val_data[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "35fe6bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of Malaysia?  ### Response: The capital of Malaysia is Kuala Lumpur.<|endoftext|>The United States is the largest economy in the world. It is the largest economy in the world.<|endoftext|>The United States is the largest economy in the world. It is the largest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personal_input = \"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is the capital of Malaysia?\n",
    "\"\"\"\n",
    "generate_and_print_sample(model, tokenizer, device, personal_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dc1c3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Provide a synonym for 'sad'.?  ### Response: A synonym for 'sad' is 'angry'.<|endoftext|>The United States is a nation of immigrants.  The United States is a melting pot of immigrants, and a melting pot of ideas.<|endoftext|>The United\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personal_input = \"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nProvide a synonym for 'sad'.?\n",
    "\"\"\"\n",
    "generate_and_print_sample(model, tokenizer, device, personal_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1ac7b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Generate a sentence using the word 'mobile phone'.?  ### Response: The phone was in the mobile phone.<|endoftext|>The United States is the largest economy in the world. It is the largest economy in the world.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personal_input = \"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a sentence using the word 'mobile phone'.?\n",
    "\"\"\"\n",
    "generate_and_print_sample(model, tokenizer, device, personal_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bd3d3",
   "metadata": {},
   "source": [
    "Training & validation loss plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e71b602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 5))\n",
    "plt.plot(train_losses, label = \"Train\")\n",
    "plt.plot(val_losses, label = \"Validation\")\n",
    "plt.xticks([0, len(train_losses)//2, len(train_losses) - 1], [0, 1, 2])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Instruction Fine-Tuning Loss Plot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
