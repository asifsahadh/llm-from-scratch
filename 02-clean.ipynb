{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d2ac6c",
   "metadata": {},
   "source": [
    "### LLM FROM SCRATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc2989",
   "metadata": {},
   "source": [
    "##### _WORKFLOW_\n",
    "1. Get tokenizer\n",
    "2. Create dataloader class for data handling\n",
    "3. Create classes for MHA, Layer Norm & Feed Forward Network\n",
    "4. Create class for the Transformer Block and add classes from point number 3\n",
    "5. Create class for the SLM and add transformer class\n",
    "6. Define function for text generation, encoding & decoding\n",
    "7. Load the dataset\n",
    "8. Create the tarin and test loader duing the dataloader class from point number 2\n",
    "9. Create functions to calculate & record the loss during training\n",
    "10. Create function for model training & train the model\n",
    "11. Implement decoding startegies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67453866",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88cf17",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7ae605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08340f",
   "metadata": {},
   "source": [
    "Get the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aae9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fea4e",
   "metadata": {},
   "source": [
    "Class to create the dataset for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9534c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_len, stride): # max_len is context size\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # tokenize the text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
    "\n",
    "        # sliding window to create overlapping sequences\n",
    "        for i in range(0, len(token_ids) - max_len, stride):\n",
    "            input_chunk = token_ids[i:i + max_len]\n",
    "            target_chunk = token_ids[i + 1:i + max_len + 1]\n",
    "            self.input_ids.append(input_chunk)\n",
    "            self.target_ids.append(target_chunk)\n",
    "    \n",
    "    # the below 2 methods is required for Dataloader to be used\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx): # we are basically saying that if the input is the 50th tensor, then the output is the 50th tensor\n",
    "        return (\n",
    "            torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            torch.tensor(self.target_ids[idx], dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af064a2",
   "metadata": {},
   "source": [
    "Helper function to create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a7cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size = 4, max_len = 256, stride = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
    "    # drop last if last tensor is shorter than max_len\n",
    "    # batch size is the number of training ip-op data pairs to be used for training by whcih the parameters are updated\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = DatasetV1(txt, tokenizer, max_len, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c54e9f",
   "metadata": {},
   "source": [
    "The MHA class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30137f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_len, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        # s2\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        # s3\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_len, context_len), diagonal = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_out = x.shape # s1\n",
    "\n",
    "        # s4\n",
    "        keys = self.W_k(x)\n",
    "        queries = self.W_q(x)\n",
    "        values = self.W_v(x)\n",
    "        \n",
    "        # s5\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # s6\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # s7\n",
    "        attention_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
    "        attention_weights = self.dropout(attention_weights) # s8\n",
    "\n",
    "        context_vec = (attention_weights @ values).transpose(1, 2) # s9 & s10\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # s11\n",
    "        context_vec = self.out_proj(context_vec) # optional\n",
    " \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562ddc5",
   "metadata": {},
   "source": [
    "Classes for layer norm, GELU activation function & feed forwards network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb87cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False) # unbiased so var is divided by n-1\n",
    "        norm = (x - mean) / (torch.sqrt(var + self.eps)) # epsilon to prevent division by 0\n",
    "        return self.scale * norm + self.shift # element wise operations - trainable parameters to learn appropriate scaling and shifting of norm values that best suits the data\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # expansion\n",
    "            GELU(), # activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # contraction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d497",
   "metadata": {},
   "source": [
    "The transformer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62c536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention( # converts input to context vectors  \n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_len = cfg[\"context_len\"],\n",
    "            num_heads = cfg[\"num_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # MHA\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) # shape: [batch size, num tokens, emb size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # f(x) + x\n",
    "\n",
    "        # FCL\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # f(x) + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0165ba",
   "metadata": {},
   "source": [
    "The SLM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbe595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLM(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_len\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_idx): # input batch\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3664aa5",
   "metadata": {},
   "source": [
    "Helper function when generating text during each epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59ab6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): # idx is the input batch\n",
    "    for _ in range(max_new_tokens):\n",
    "        # crop current context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # get predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # batch_size x tokens_num x vocab_size\n",
    "        # get the last time step (last set of logits)\n",
    "        logits = logits[:, -1, :]\n",
    "        # apply softmax\n",
    "        probs = torch.softmax(logits, dim = -1)\n",
    "        # get id of max\n",
    "        idx_next = torch.argmax(probs, dim = -1, keepdim = True)\n",
    "        # append id to running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim = -1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306da6",
   "metadata": {},
   "source": [
    "Configure model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6172c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLM_CONFIG = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_len\" : 512,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"num_heads\" : 8, # attention heads\n",
    "    \"n_layers\" : 8, # transformer blocks\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae7919",
   "metadata": {},
   "source": [
    "Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bcbb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLM(SLM_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9f724",
   "metadata": {},
   "source": [
    "Function for encoding & decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257c7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad055a60",
   "metadata": {},
   "source": [
    "Load Openweb text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df87da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for whole dataset: 3,378,008,151\n"
     ]
    }
   ],
   "source": [
    "data = np.memmap(\"train.bin\", dtype = np.uint16, mode = \"r\")\n",
    "print(\"Number of tokens for whole dataset:\", f\"{len(data):,}\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a50d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for small dataset: 16,890,040\n"
     ]
    }
   ],
   "source": [
    "small = int(len(data) / 200)\n",
    "print(\"Number of tokens for small dataset:\", f\"{len(data[:small]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02add6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "raw_text = enc.decode(data[:small])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f98ed7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load the text data: 0.084 minutes\n",
      "Sample text: Freedom and democracy are said to be guarantees of human rights, but as the NSA spying scandal recently showed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken to load the text data: {(end - start) / 60:.3f} minutes\")\n",
    "print(f\"Sample text: {raw_text[:110]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccb530",
   "metadata": {},
   "source": [
    "Adding personal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "706e6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me.txt\", \"r\", encoding = \"utf-8\") as t:\n",
    "    personal_text = t.read()\n",
    "\n",
    "raw_text += personal_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de870b8e",
   "metadata": {},
   "source": [
    "Create data loader (a.k.a, PyTorch way of making train-test-splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f39a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "test_data = raw_text[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_len = SLM_CONFIG[\"context_len\"],\n",
    "    stride = SLM_CONFIG[\"context_len\"],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader_v1(\n",
    "    test_data,\n",
    "    batch_size = 2,\n",
    "    max_len = SLM_CONFIG[\"context_len\"],\n",
    "    stride = SLM_CONFIG[\"context_len\"],\n",
    "    drop_last = False,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1451cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe391a",
   "metadata": {},
   "source": [
    "Functions to calculate loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f3b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten()) # this does all the softmax & everything\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches = None): # this will show the loss of the LM\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches # mean loss per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f43f02",
   "metadata": {},
   "source": [
    "Function to record loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0102f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation function\n",
    "def evaluate_model(model, train_loader, test_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
    "        test_loss = calc_loss_loader(test_loader, model, device, num_batches = eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe3ca0",
   "metadata": {},
   "source": [
    "Function to generate text after each epoch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b32cd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model, idx = encoded, max_new_tokens = 50, context_size = context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    print()\n",
    "    model.train() # set it back to training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a87ef",
   "metadata": {},
   "source": [
    "Function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4399ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, test_loader, optimizer, device, \n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, test_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset gradients from previous batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel() # return number of tokens seen\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation (optional)\n",
    "            if global_step % eval_freq == 0: # only after a set of batches is used for training\n",
    "                train_loss, test_loss = evaluate_model(\n",
    "                    model, train_loader, test_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                test_losses.append(test_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch + 1} (Step {global_step:04d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Test loss {test_loss:.3f}\")\n",
    "            \n",
    "        # print sample text from each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "        \n",
    "    return train_losses, test_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9c0f1",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13614a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SLM(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(512, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "686a19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters to train: 134,274,048\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters to train: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b241282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 0000): Train loss 10.252, Test loss 10.256\n",
      "Epoch 1 (Step 0500): Train loss 6.927, Test loss 6.985\n",
      "Epoch 1 (Step 1000): Train loss 6.755, Test loss 6.827\n",
      "Epoch 1 (Step 1500): Train loss 6.528, Test loss 6.625\n",
      "Epoch 1 (Step 2000): Train loss 6.458, Test loss 6.542\n",
      "Epoch 1 (Step 2500): Train loss 6.358, Test loss 6.486\n",
      "Epoch 1 (Step 3000): Train loss 6.308, Test loss 6.409\n",
      "Epoch 1 (Step 3500): Train loss 6.275, Test loss 6.379\n",
      "Epoch 1 (Step 4000): Train loss 6.202, Test loss 6.334\n",
      "Epoch 1 (Step 4500): Train loss 6.172, Test loss 6.303\n",
      "Epoch 1 (Step 5000): Train loss 6.132, Test loss 6.276\n",
      "Epoch 1 (Step 5500): Train loss 6.072, Test loss 6.251\n",
      "Epoch 1 (Step 6000): Train loss 6.027, Test loss 6.204\n",
      "Epoch 1 (Step 6500): Train loss 6.035, Test loss 6.207\n",
      "Epoch 1 (Step 7000): Train loss 6.030, Test loss 6.181\n",
      "Epoch 1 (Step 7500): Train loss 6.000, Test loss 6.183\n",
      "Epoch 1 (Step 8000): Train loss 5.971, Test loss 6.139\n",
      "Epoch 1 (Step 8500): Train loss 5.968, Test loss 6.130\n",
      "Epoch 1 (Step 9000): Train loss 5.942, Test loss 6.109\n",
      "Epoch 1 (Step 9500): Train loss 5.886, Test loss 6.081\n",
      "Epoch 1 (Step 10000): Train loss 5.889, Test loss 6.056\n",
      "Epoch 1 (Step 10500): Train loss 5.899, Test loss 6.063\n",
      "Epoch 1 (Step 11000): Train loss 5.866, Test loss 6.072\n",
      "Epoch 1 (Step 11500): Train loss 5.816, Test loss 6.019\n",
      "Epoch 1 (Step 12000): Train loss 5.832, Test loss 6.009\n",
      "Epoch 1 (Step 12500): Train loss 5.778, Test loss 5.982\n",
      "Epoch 1 (Step 13000): Train loss 5.775, Test loss 5.982\n",
      "Epoch 1 (Step 13500): Train loss 5.745, Test loss 5.944\n",
      "Epoch 1 (Step 14000): Train loss 5.706, Test loss 5.931\n",
      "Epoch 1 (Step 14500): Train loss 5.686, Test loss 5.900\n",
      "What are human rights?  The woman who have been a woman who have been a woman who was a woman who was a woman who was not a woman who were not a woman who was not a woman who were not a woman who was not a woman who were not\n",
      "\n",
      "Epoch 2 (Step 15000): Train loss 5.670, Test loss 5.894\n",
      "Epoch 2 (Step 15500): Train loss 5.632, Test loss 5.880\n",
      "Epoch 2 (Step 16000): Train loss 5.627, Test loss 5.857\n",
      "Epoch 2 (Step 16500): Train loss 5.569, Test loss 5.812\n",
      "Epoch 2 (Step 17000): Train loss 5.551, Test loss 5.791\n",
      "Epoch 2 (Step 17500): Train loss 5.554, Test loss 5.794\n",
      "Epoch 2 (Step 18000): Train loss 5.523, Test loss 5.737\n",
      "Epoch 2 (Step 18500): Train loss 5.464, Test loss 5.703\n",
      "Epoch 2 (Step 19000): Train loss 5.426, Test loss 5.692\n",
      "Epoch 2 (Step 19500): Train loss 5.427, Test loss 5.677\n",
      "Epoch 2 (Step 20000): Train loss 5.387, Test loss 5.648\n",
      "Epoch 2 (Step 20500): Train loss 5.342, Test loss 5.643\n",
      "Epoch 2 (Step 21000): Train loss 5.319, Test loss 5.601\n",
      "Epoch 2 (Step 21500): Train loss 5.299, Test loss 5.578\n",
      "Epoch 2 (Step 22000): Train loss 5.282, Test loss 5.552\n",
      "Epoch 2 (Step 22500): Train loss 5.233, Test loss 5.537\n",
      "Epoch 2 (Step 23000): Train loss 5.219, Test loss 5.528\n",
      "Epoch 2 (Step 23500): Train loss 5.229, Test loss 5.508\n",
      "Epoch 2 (Step 24000): Train loss 5.191, Test loss 5.491\n",
      "Epoch 2 (Step 24500): Train loss 5.204, Test loss 5.470\n",
      "Epoch 2 (Step 25000): Train loss 5.173, Test loss 5.457\n",
      "Epoch 2 (Step 25500): Train loss 5.152, Test loss 5.469\n",
      "Epoch 2 (Step 26000): Train loss 5.105, Test loss 5.416\n",
      "Epoch 2 (Step 26500): Train loss 5.080, Test loss 5.400\n",
      "Epoch 2 (Step 27000): Train loss 5.052, Test loss 5.372\n",
      "Epoch 2 (Step 27500): Train loss 5.036, Test loss 5.372\n",
      "Epoch 2 (Step 28000): Train loss 5.049, Test loss 5.371\n",
      "Epoch 2 (Step 28500): Train loss 4.998, Test loss 5.344\n",
      "Epoch 2 (Step 29000): Train loss 4.987, Test loss 5.341\n",
      "Epoch 2 (Step 29500): Train loss 4.996, Test loss 5.317\n",
      "What are human rights?  “I don’t think it’s not a good way to do it.”  “I’m not going to be a good idea of how to do it,” he said.\n",
      "\n",
      "Epoch 3 (Step 30000): Train loss 4.995, Test loss 5.327\n",
      "Epoch 3 (Step 30500): Train loss 4.922, Test loss 5.304\n",
      "Epoch 3 (Step 31000): Train loss 4.915, Test loss 5.307\n",
      "Epoch 3 (Step 31500): Train loss 4.926, Test loss 5.285\n",
      "Epoch 3 (Step 32000): Train loss 4.880, Test loss 5.285\n",
      "Epoch 3 (Step 32500): Train loss 4.889, Test loss 5.279\n",
      "Epoch 3 (Step 33000): Train loss 4.868, Test loss 5.275\n",
      "Epoch 3 (Step 33500): Train loss 4.857, Test loss 5.259\n",
      "Epoch 3 (Step 34000): Train loss 4.814, Test loss 5.230\n",
      "Epoch 3 (Step 34500): Train loss 4.836, Test loss 5.242\n",
      "Epoch 3 (Step 35000): Train loss 4.806, Test loss 5.221\n",
      "Epoch 3 (Step 35500): Train loss 4.808, Test loss 5.222\n",
      "Epoch 3 (Step 36000): Train loss 4.796, Test loss 5.211\n",
      "Epoch 3 (Step 36500): Train loss 4.756, Test loss 5.202\n",
      "Epoch 3 (Step 37000): Train loss 4.767, Test loss 5.181\n",
      "Epoch 3 (Step 37500): Train loss 4.783, Test loss 5.174\n",
      "Epoch 3 (Step 38000): Train loss 4.737, Test loss 5.155\n",
      "Epoch 3 (Step 38500): Train loss 4.733, Test loss 5.157\n",
      "Epoch 3 (Step 39000): Train loss 4.719, Test loss 5.145\n",
      "Epoch 3 (Step 39500): Train loss 4.678, Test loss 5.133\n",
      "Epoch 3 (Step 40000): Train loss 4.707, Test loss 5.137\n",
      "Epoch 3 (Step 40500): Train loss 4.705, Test loss 5.139\n",
      "Epoch 3 (Step 41000): Train loss 4.697, Test loss 5.123\n",
      "Epoch 3 (Step 41500): Train loss 4.684, Test loss 5.113\n",
      "Epoch 3 (Step 42000): Train loss 4.665, Test loss 5.115\n",
      "Epoch 3 (Step 42500): Train loss 4.676, Test loss 5.091\n",
      "Epoch 3 (Step 43000): Train loss 4.657, Test loss 5.085\n",
      "Epoch 3 (Step 43500): Train loss 4.625, Test loss 5.076\n",
      "Epoch 3 (Step 44000): Train loss 4.635, Test loss 5.075\n",
      "Epoch 3 (Step 44500): Train loss 4.624, Test loss 5.061\n",
      "What are human rights?  The problem is that it is that it is not a problem. It is not a problem. It is not a problem. It is not a problem. It is not a problem. It is not a problem. It is not a problem\n",
      "\n",
      "Epoch 4 (Step 45000): Train loss 4.590, Test loss 5.084\n",
      "Epoch 4 (Step 45500): Train loss 4.606, Test loss 5.085\n",
      "Epoch 4 (Step 46000): Train loss 4.593, Test loss 5.081\n",
      "Epoch 4 (Step 46500): Train loss 4.569, Test loss 5.063\n",
      "Epoch 4 (Step 47000): Train loss 4.545, Test loss 5.060\n",
      "Epoch 4 (Step 47500): Train loss 4.549, Test loss 5.067\n",
      "Epoch 4 (Step 48000): Train loss 4.557, Test loss 5.054\n",
      "Epoch 4 (Step 48500): Train loss 4.552, Test loss 5.052\n",
      "Epoch 4 (Step 49000): Train loss 4.507, Test loss 5.047\n",
      "Epoch 4 (Step 49500): Train loss 4.527, Test loss 5.027\n",
      "Epoch 4 (Step 50000): Train loss 4.488, Test loss 5.027\n",
      "Epoch 4 (Step 50500): Train loss 4.522, Test loss 5.026\n",
      "Epoch 4 (Step 51000): Train loss 4.482, Test loss 5.012\n",
      "Epoch 4 (Step 51500): Train loss 4.529, Test loss 5.017\n",
      "Epoch 4 (Step 52000): Train loss 4.517, Test loss 5.009\n",
      "Epoch 4 (Step 52500): Train loss 4.473, Test loss 5.007\n",
      "Epoch 4 (Step 53000): Train loss 4.463, Test loss 4.998\n",
      "Epoch 4 (Step 53500): Train loss 4.471, Test loss 4.985\n",
      "Epoch 4 (Step 54000): Train loss 4.469, Test loss 4.980\n",
      "Epoch 4 (Step 54500): Train loss 4.421, Test loss 4.977\n",
      "Epoch 4 (Step 55000): Train loss 4.466, Test loss 4.969\n",
      "Epoch 4 (Step 55500): Train loss 4.448, Test loss 4.969\n",
      "Epoch 4 (Step 56000): Train loss 4.484, Test loss 4.983\n",
      "Epoch 4 (Step 56500): Train loss 4.402, Test loss 4.949\n",
      "Epoch 4 (Step 57000): Train loss 4.440, Test loss 4.955\n",
      "Epoch 4 (Step 57500): Train loss 4.439, Test loss 4.956\n",
      "Epoch 4 (Step 58000): Train loss 4.418, Test loss 4.933\n",
      "Epoch 4 (Step 58500): Train loss 4.435, Test loss 4.939\n",
      "Epoch 4 (Step 59000): Train loss 4.400, Test loss 4.936\n",
      "What are human rights?  The first thing that I can do is to be a good person. I don’t want to be a good person. I don’t want to be a good person. I don’t want to be a good\n",
      "\n",
      "Epoch 5 (Step 59500): Train loss 4.389, Test loss 4.922\n",
      "Epoch 5 (Step 60000): Train loss 4.373, Test loss 4.934\n",
      "Epoch 5 (Step 60500): Train loss 4.368, Test loss 4.937\n",
      "Epoch 5 (Step 61000): Train loss 4.373, Test loss 4.954\n",
      "Epoch 5 (Step 61500): Train loss 4.362, Test loss 4.939\n",
      "Epoch 5 (Step 62000): Train loss 4.346, Test loss 4.930\n",
      "Epoch 5 (Step 62500): Train loss 4.325, Test loss 4.928\n",
      "Epoch 5 (Step 63000): Train loss 4.308, Test loss 4.925\n",
      "Epoch 5 (Step 63500): Train loss 4.371, Test loss 4.931\n",
      "Epoch 5 (Step 64000): Train loss 4.317, Test loss 4.913\n",
      "Epoch 5 (Step 64500): Train loss 4.347, Test loss 4.919\n",
      "Epoch 5 (Step 65000): Train loss 4.332, Test loss 4.904\n",
      "Epoch 5 (Step 65500): Train loss 4.329, Test loss 4.895\n",
      "Epoch 5 (Step 66000): Train loss 4.271, Test loss 4.889\n",
      "Epoch 5 (Step 66500): Train loss 4.334, Test loss 4.907\n",
      "Epoch 5 (Step 67000): Train loss 4.303, Test loss 4.882\n",
      "Epoch 5 (Step 67500): Train loss 4.293, Test loss 4.887\n",
      "Epoch 5 (Step 68000): Train loss 4.290, Test loss 4.871\n",
      "Epoch 5 (Step 68500): Train loss 4.277, Test loss 4.875\n",
      "Epoch 5 (Step 69000): Train loss 4.274, Test loss 4.867\n",
      "Epoch 5 (Step 69500): Train loss 4.292, Test loss 4.864\n",
      "Epoch 5 (Step 70000): Train loss 4.259, Test loss 4.855\n",
      "Epoch 5 (Step 70500): Train loss 4.228, Test loss 4.846\n",
      "Epoch 5 (Step 71000): Train loss 4.291, Test loss 4.851\n",
      "Epoch 5 (Step 71500): Train loss 4.251, Test loss 4.850\n",
      "Epoch 5 (Step 72000): Train loss 4.228, Test loss 4.841\n",
      "Epoch 5 (Step 72500): Train loss 4.225, Test loss 4.831\n",
      "Epoch 5 (Step 73000): Train loss 4.278, Test loss 4.840\n",
      "Epoch 5 (Step 73500): Train loss 4.260, Test loss 4.834\n",
      "Epoch 5 (Step 74000): Train loss 4.208, Test loss 4.817\n",
      "What are human rights?  The idea is that the government is not a member of the United States, but the government is not a member of the United States.  The government is not a member of the United States, but the government is not a member of\n",
      "\n",
      "Training completed in 373.84 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = SLM(SLM_CONFIG)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay = 0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, test_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, test_loader, optimizer, device, \n",
    "    num_epochs = num_epochs, eval_freq = 500, eval_iter = 500, # after every 500 batches, training and validation loss will be printed\n",
    "    start_context = \"What are human rights?\", tokenizer = tokenizer\n",
    ") \n",
    "\n",
    "end = time.time()\n",
    "training_time = (end - start) / 60\n",
    "print(f\"Training completed in {training_time:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac416e00",
   "metadata": {},
   "source": [
    "Visualizing the loss plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1de3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7, 4))\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.plot(epochs, train_losses, label = 'Training Loss', color = '#2E86AB', linewidth = 1)\n",
    "plt.plot(epochs, test_losses, label = 'Testing Loss', color = '#F24236', linewidth = 1, linestyle='--')\n",
    "\n",
    "plt.title(\"Training & Testing Loss\", fontsize = 14, pad = 10)\n",
    "plt.xlabel(\"Epoch\", fontsize = 10)\n",
    "plt.ylabel(\"Loss\", fontsize = 10)\n",
    "\n",
    "plt.legend(frameon = True, fancybox = True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263e606",
   "metadata": {},
   "source": [
    "Function to implement decoding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28bfab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature = 0.0, top_k = None, eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, \n",
    "                torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "            \n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66377da8",
   "metadata": {},
   "source": [
    "Text generation after applying decoding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "236957dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: I used to think about this kind of stuff. It was a lot of stuff because it was bad. I knew he’d like the show about a bit too much than he did about to get it because he wanted to see the show that it had a good show. This time we would see the film was just something I can find\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model = model, \n",
    "    idx = text_to_token_ids(\"I used to think\", tokenizer).to(device),\n",
    "    max_new_tokens = 65,\n",
    "    context_size = SLM_CONFIG[\"context_len\"],\n",
    "    top_k = 25,\n",
    "    temperature = 1.4\n",
    ")\n",
    "\n",
    "print(\"Output:\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
