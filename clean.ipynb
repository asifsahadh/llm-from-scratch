{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d2ac6c",
   "metadata": {},
   "source": [
    "### LLM FROM SCRATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc2989",
   "metadata": {},
   "source": [
    "##### _WORKFLOW_\n",
    "1. Get tokenizer\n",
    "2. Create dataloader class for data handling\n",
    "3. Create classes for MHA, Layer Norm & Feed Forward Network\n",
    "4. Create class for the Transformer Block and add classes from point number 3\n",
    "5. Create class for the SLM and add transformer class\n",
    "6. Define function for text generation, encoding & decoding\n",
    "7. Load the dataset\n",
    "8. Create the tarin and test loader duing the dataloader class from point number 2\n",
    "9. Create functions to calculate & record the loss during training\n",
    "10. Create function for model training & train the model\n",
    "11. Implement decoding startegies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67453866",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88cf17",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7ae605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08340f",
   "metadata": {},
   "source": [
    "Get the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aae9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fea4e",
   "metadata": {},
   "source": [
    "Class to create the dataset for out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9534c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_len, stride): # max_len is context size\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # tokenize the text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
    "\n",
    "        # sliding window to create overlapping sequences\n",
    "        for i in range(0, len(token_ids) - max_len, stride):\n",
    "            input_chunk = token_ids[i:i + max_len]\n",
    "            target_chunk = token_ids[i + 1:i + max_len + 1]\n",
    "            self.input_ids.append(input_chunk)\n",
    "            self.target_ids.append(target_chunk)\n",
    "    \n",
    "    # the below 2 methods is required for Dataloader to be used\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx): # we are basically saying that if the input is the 50th tensor, then the output is the 50th tensor\n",
    "        return (\n",
    "            torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            torch.tensor(self.target_ids[idx], dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af064a2",
   "metadata": {},
   "source": [
    "Helper function to create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a7cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size = 4, max_len = 256, stride = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
    "    # drop last if last tensor is shorter than max_len\n",
    "    # batch size is the number of training ip-op data pairs to be used for training by whcih the parameters are updated\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = DatasetV1(txt, tokenizer, max_len, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c54e9f",
   "metadata": {},
   "source": [
    "The MHA class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30137f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_len, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        # s2\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        # s3\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_len, context_len), diagonal = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_out = x.shape # s1\n",
    "\n",
    "        # s4\n",
    "        keys = self.W_k(x)\n",
    "        queries = self.W_q(x)\n",
    "        values = self.W_v(x)\n",
    "        \n",
    "        # s5\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # s6\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # s7\n",
    "        attention_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
    "        attention_weights = self.dropout(attention_weights) # s8\n",
    "\n",
    "        context_vec = (attention_weights @ values).transpose(1, 2) # s9 & s10\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # s11\n",
    "        context_vec = self.out_proj(context_vec) # optional\n",
    " \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562ddc5",
   "metadata": {},
   "source": [
    "Classes for layer norm, GELU activation function & feed forwards network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb87cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False) # unbiased so var is divided by n-1\n",
    "        norm = (x - mean) / (torch.sqrt(var + self.eps)) # epsilon to prevent division by 0\n",
    "        return self.scale * norm + self.shift # element wise operations - trainable parameters to learn appropriate scaling and shifting of norm values that best suits the data\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # expansion\n",
    "            GELU(), # activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # contraction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d497",
   "metadata": {},
   "source": [
    "The transformer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62c536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention( # converts input to context vectors  \n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_len = cfg[\"context_len\"],\n",
    "            num_heads = cfg[\"num_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # MHA\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) # shape: [batch size, num tokens, emb size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # f(x) + x\n",
    "\n",
    "        # FCL\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # f(x) + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0165ba",
   "metadata": {},
   "source": [
    "The SLM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbe595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLM(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_len\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_idx): # input batch\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3664aa5",
   "metadata": {},
   "source": [
    "Helper function when generating text during each epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59ab6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): # idx is the input batch\n",
    "    for _ in range(max_new_tokens):\n",
    "        # crop current context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # get predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # batch_size x tokens_num x vocab_size\n",
    "        # get the last time step (last set of logits)\n",
    "        logits = logits[:, -1, :]\n",
    "        # apply softmax\n",
    "        probs = torch.softmax(logits, dim = -1)\n",
    "        # get id of max\n",
    "        idx_next = torch.argmax(probs, dim = -1, keepdim = True)\n",
    "        # append id to running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim = -1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306da6",
   "metadata": {},
   "source": [
    "Configure model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6172c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLM_CONFIG = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_len\" : 512,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"num_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae7919",
   "metadata": {},
   "source": [
    "Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bcbb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLM(SLM_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9f724",
   "metadata": {},
   "source": [
    "Function for encoding & decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257c7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad055a60",
   "metadata": {},
   "source": [
    "Load Openweb text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df87da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for whole dataset: 3,378,008,151\n"
     ]
    }
   ],
   "source": [
    "data = np.memmap(\"train.bin\", dtype = np.uint16, mode = \"r\")\n",
    "print(\"Number of tokens for whole dataset:\", f\"{len(data):,}\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a50d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for small dataset: 337,800,815\n"
     ]
    }
   ],
   "source": [
    "small = int(len(data) / 10)\n",
    "print(\"Number of tokens for small dataset:\", f\"{len(data[:small]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02add6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "raw_text = enc.decode(data[:small])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f98ed7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load the text data: 1.31 minutes\n",
      "Sample text: Freedom and democracy are said to be guarantees of human rights, but as the NSA spying scandal recently showed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken to load the text data: {(end - start) / 60:.2f} minutes\")\n",
    "print(f\"Sample text: {raw_text[:110]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccb530",
   "metadata": {},
   "source": [
    "Adding personal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "706e6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me.txt\", \"r\", encoding = \"utf-8\") as t:\n",
    "    personal_text = t.read()\n",
    "\n",
    "raw_text += personal_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de870b8e",
   "metadata": {},
   "source": [
    "Create data loader (a.k.a, PyTorch way of making train-test-splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb47c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = len(tokenizer.encode(raw_text, allowed_special = {\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f39a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "test_data = raw_text[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_len = SLM_CONFIG[\"context_len\"],\n",
    "    stride = SLM_CONFIG[\"context_len\"],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader_v1(\n",
    "    test_data,\n",
    "    batch_size = 2,\n",
    "    max_len = SLM_CONFIG[\"context_len\"],\n",
    "    stride = SLM_CONFIG[\"context_len\"],\n",
    "    drop_last = False,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe391a",
   "metadata": {},
   "source": [
    "Functions to calculate loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f3b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten()) # this does all the softmax & everything\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches = None): # this will show the loss of the LM\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches # mean loss per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f43f02",
   "metadata": {},
   "source": [
    "Function to record loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0102f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation function\n",
    "def evaluate_model(model, train_loader, test_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
    "        test_loss = calc_loss_loader(test_loader, model, device, num_batches = eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe3ca0",
   "metadata": {},
   "source": [
    "Function to generate text after each epoch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b32cd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model, idx = encoded, max_new_tokens = 50, context_size = context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    print()\n",
    "    model.train() # set it back to training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a87ef",
   "metadata": {},
   "source": [
    "Function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4399ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, test_loader, optimizer, device, \n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, test_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset gradients from previous batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel() # return number of tokens seen\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation (optional)\n",
    "            if global_step % eval_freq == 0: # only after a set of batches is used for training\n",
    "                train_loss, test_loss = evaluate_model(\n",
    "                    model, train_loader, test_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                test_losses.append(test_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch + 1} (Step {global_step:04d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Test loss {test_loss:.3f}\")\n",
    "            \n",
    "        # print sample text from each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "        \n",
    "    return train_losses, test_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9c0f1",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13614a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SLM(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(512, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "686a19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters to train: 162,616,320\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters to train: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b241282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = SLM(SLM_CONFIG)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay = 0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "train_losses, test_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, test_loader, optimizer, device, \n",
    "    num_epochs = num_epochs, eval_freq = 500, eval_iter = 500, # after every 500 batches, training and validation loss will be printed\n",
    "    start_context = \"Who is Asif?\", tokenizer = tokenizer\n",
    ") \n",
    "\n",
    "end = time.time()\n",
    "training_time = (end - start) / 60\n",
    "print(f\"Training completed in {training_time:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac416e00",
   "metadata": {},
   "source": [
    "Visualizing the loss plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7, 4))\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.plot(epochs, train_losses, label = 'Training Loss', color = '#2E86AB', linewidth = 1)\n",
    "plt.plot(epochs, test_losses, label = 'Testing Loss', color = '#F24236', linewidth = 1, linestyle='--')\n",
    "\n",
    "plt.title(\"Training & Testing Loss\", fontsize = 14, pad = 10)\n",
    "plt.xlabel(\"Epoch\", fontsize = 10)\n",
    "plt.ylabel(\"Loss\", fontsize = 10)\n",
    "\n",
    "plt.legend(frameon = True, fancybox = True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263e606",
   "metadata": {},
   "source": [
    "Function to implement decoding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature = 0.0, top_k = None, eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, \n",
    "                torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "            \n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66377da8",
   "metadata": {},
   "source": [
    "Text generation after applying decoding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236957dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(246)\n",
    "\n",
    "token_ids = generate(\n",
    "    model = model, \n",
    "    idx = text_to_token_ids(\"Asif likes to\", tokenizer).to(device),\n",
    "    max_new_tokens = 65,\n",
    "    context_size = SLM_CONFIG[\"context_len\"],\n",
    "    top_k = 25,\n",
    "    temperature = 1.4\n",
    ")\n",
    "\n",
    "print(\"Output:\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
